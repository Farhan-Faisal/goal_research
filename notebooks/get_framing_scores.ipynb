{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48ac67ac",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Text containing conditional triggers (“if/when/after [context], I will [behavior]”) predicts higher next-day completion, especially for high-effort goals. We have two goals in text formats per day. However, most people do not write explicit conditional triggers. Using an LLM, we can rate each goal for implicit or explicit conditional trigger phrasing (e.g., “after work”, “before bed”, “tonight”, “on weekends”, etc). \n",
    "\n",
    "We are gonna have a categorical scale of 0, 1, and 2:\n",
    "- 0 means no implicit or explicit cue  or planning specificity phrasing\n",
    "- 1 means some implicit or explicit cue or planning specificity phrasing\n",
    "- 2 means strong implicit or explicit cue or planning specificity phrasing\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0efbf179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from typing import List\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70fac5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22dda5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.handle_batches import (\n",
    "    get_required_batches, write_log\n",
    ")\n",
    "\n",
    "from utils.llm_utils import get_batch_classification_by_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47836eab",
   "metadata": {},
   "source": [
    "___\n",
    "CONFIGURE THE PATHS\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7679cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2aaa9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_report_path = \"../data/proc/self_report/self_report.csv\" \n",
    "results_path = '../results/'\n",
    "classification_log_path = \"../data/logs/framing_log.json\"\n",
    "classification_output_path = results_path + \"batch_conditional_trigger_results/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f985cf3",
   "metadata": {},
   "source": [
    "___\n",
    "PREPARE THE DATA DICTIONARY\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e64d9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(self_report_path)\n",
    "\n",
    "cols = [\n",
    "    \"ParticipantIdentifier\",\n",
    "    \"trial_date\",\n",
    "    \"DAILY_goal1_set\",\n",
    "    \"DAILY_goal2_set\",\n",
    "]\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "long_df = pd.melt(\n",
    "    df,\n",
    "    id_vars=[\"ParticipantIdentifier\", \"trial_date\"],   # keep these as identifiers\n",
    "    value_vars=[\"DAILY_goal1_set\", \"DAILY_goal2_set\"],  # the columns to melt\n",
    "    var_name=\"ResponseIdentifier\",   # new column for the old column names\n",
    "    value_name=\"Answers\"             # new column for the values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0650d3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "goalDF = long_df\n",
    "\n",
    "df_dict = goalDF.to_dict('records')\n",
    "for i in range(len(df_dict)):\n",
    "    try:\n",
    "        df_dict[i]['Answers'] = df_dict[i]['Answers'].strip()\n",
    "    except:\n",
    "        df_dict[i]['Answers'] =str(df_dict[i]['Answers']).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcd47f2",
   "metadata": {},
   "source": [
    "___\n",
    "CONFIGURE THE PROMPT\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1ad4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Label(BaseModel):\n",
    "    goals: List[dict[str,int]] = Field(description=\"List of goals-[conditional-trigger-or-framing-score] pairs\")\n",
    "    \n",
    "parser = PydanticOutputParser(pydantic_object=Label)\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert in psychology and goal-setting research.\n",
    "\n",
    "Rate each goal from **0, 1, and 2** for how much it shows **planning specificity or cue-based phrasing** — \n",
    "meaning that the goal contains *any* hint of timing, place, routine, or sequencing.\n",
    "\n",
    "Do **not** require explicit “if/when/after” language; partial or implicit cues still count.\n",
    "---\n",
    "\n",
    "### Scoring Rubric\n",
    "\n",
    "0 means no implicit or explicit cue  or planning specificity phrasing\n",
    "1 means some implicit or explicit cue or planning specificity phrasing\n",
    "2 means strong implicit or explicit cue or planning specificity phrasing\n",
    "---\n",
    "\n",
    "**Guidelines:**\n",
    "- Use **whole numbers only (0–10)**.\n",
    "\n",
    "---\n",
    "\n",
    "### Output format\n",
    "{format_instructions}\n",
    "\n",
    "Return a list of dictionaries:\n",
    "- key = exact goal text\n",
    "- value = numeric score (0–10)\n",
    "\n",
    "No other commentary.\n",
    "\n",
    "---\n",
    "\n",
    "GOALS:\n",
    "{goalList}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"goalList\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e2752f",
   "metadata": {},
   "source": [
    "___\n",
    "CONFIGURE THE MODEL TO BE USED\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f42b7cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model to be used\n",
    "model_name = 'gpt-4o'\n",
    "temperature = 0.5\n",
    "llm = ChatOpenAI(model=model_name, temperature=temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122cf893",
   "metadata": {},
   "source": [
    "___\n",
    "CONFIGURE THE BATCHES\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24fb0de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985]\n"
     ]
    }
   ],
   "source": [
    "required_batches = get_required_batches(goalDF)\n",
    "print(required_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2dd7f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985] 25\n"
     ]
    }
   ],
   "source": [
    "## GET COMPLETED BATCHES AND BATCH SIZE\n",
    "completed_batches = []\n",
    "batch_size = 0\n",
    "import json\n",
    "with open(classification_log_path, \"r\") as file:\n",
    "    loaded_json = json.load(file)\n",
    "    loaded_json = json.loads(loaded_json)\n",
    "    completed_batches = loaded_json['completed_batches']\n",
    "    batch_size = loaded_json['batch_size']\n",
    "    print(completed_batches, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe4a90f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# completed_batches = [x for x in range(1, 836)]\n",
    "batch_list = [item for item in required_batches if item not in completed_batches]\n",
    "print(batch_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31c0e49",
   "metadata": {},
   "source": [
    "___\n",
    "DO THE LLM CALLS TO GET THE SCORES\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb3a2171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>ResponseIdentifier</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0501ba67-3406-4779-aff1-878a0e9f7885</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>DAILY_goal1_set</td>\n",
       "      <td>Study history and psychology, practice the vio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0501ba67-3406-4779-aff1-878a0e9f7885</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>DAILY_goal1_set</td>\n",
       "      <td>study history lectures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0501ba67-3406-4779-aff1-878a0e9f7885</td>\n",
       "      <td>2022-10-02</td>\n",
       "      <td>DAILY_goal1_set</td>\n",
       "      <td>Watch a historical movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date ResponseIdentifier  \\\n",
       "0  0501ba67-3406-4779-aff1-878a0e9f7885  2022-09-30    DAILY_goal1_set   \n",
       "1  0501ba67-3406-4779-aff1-878a0e9f7885  2022-10-01    DAILY_goal1_set   \n",
       "2  0501ba67-3406-4779-aff1-878a0e9f7885  2022-10-02    DAILY_goal1_set   \n",
       "\n",
       "                                             Answers  \n",
       "0  Study history and psychology, practice the vio...  \n",
       "1                             study history lectures  \n",
       "2                           Watch a historical movie  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ead0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conditional_trigger_rating(batch_list, completed_batches, batch_size, \n",
    "                   df_dict, model_name, temperature, prompt,\n",
    "                   output_directory, file_suffix, classification_log_path):\n",
    "\n",
    "    Labels = []\n",
    "    for item in tqdm(batch_list):\n",
    "        if item in completed_batches:\n",
    "            continue\n",
    "        else:\n",
    "            end_index = item*batch_size\n",
    "            start_index = end_index - batch_size\n",
    "            print(item, start_index, end_index)\n",
    "\n",
    "            Labels = get_batch_classification_by_llm(\n",
    "                Label, \n",
    "                df_dict, \n",
    "                llm, prompt, \n",
    "                start_index, end_index\n",
    "            )\n",
    "            \n",
    "            print(Labels)\n",
    "            print(len(Labels))\n",
    "            completed_batches.append(item)\n",
    "\n",
    "            for i in range(len(Labels)):\n",
    "                try:\n",
    "                    df_dict[i + start_index]['framing_score'] = list(Labels[i].values())[0] \n",
    "                except KeyError:\n",
    "                    df_dict[i + start_index]['framing_score'] = \"!!!FIX_ME!!!\"\n",
    "\n",
    "            pd.DataFrame(df_dict[start_index:end_index]).to_csv(output_directory + \"/\" + file_suffix + \"_\" + str(item) + \".csv\")\n",
    "\n",
    "    write_log(completed_batches, batch_size, classification_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_conditional_trigger_rating(batch_list, completed_batches, 25, \n",
    "                df_dict, model_name, temperature, prompt,\n",
    "                classification_output_path, 'batch', classification_log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a52a017",
   "metadata": {},
   "source": [
    "___\n",
    "CONCATENATE DICTIONARIES AND SAVE OUTPUT\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a92a320",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = []\n",
    "\n",
    "batches = [(i + 1) for i in range(len(\n",
    "    [name for name in os.listdir(classification_output_path) if not name.startswith('fixed')]\n",
    "    ))]\n",
    "\n",
    "for i in batches:\n",
    "    filename = \"batch\" + \"_\" + str(i) + \".csv\"\n",
    "    file_path = os.path.join(classification_output_path, filename)\n",
    "    if os.path.isfile(file_path): # checking if it is a file\n",
    "        df_temp = pd.read_csv(file_path).to_dict('records')\n",
    "        for x in df_temp:\n",
    "            df_dict.append(x) \n",
    "\n",
    "labelledDF = pd.DataFrame.from_dict(df_dict).reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3819ebfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParticipantIdentifier</th>\n",
       "      <th>trial_date</th>\n",
       "      <th>ResponseIdentifier</th>\n",
       "      <th>Answers</th>\n",
       "      <th>framing_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0501ba67-3406-4779-aff1-878a0e9f7885</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>DAILY_goal1_set</td>\n",
       "      <td>Study history and psychology, practice the violin</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0501ba67-3406-4779-aff1-878a0e9f7885</td>\n",
       "      <td>2022-10-01</td>\n",
       "      <td>DAILY_goal1_set</td>\n",
       "      <td>study history lectures</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0501ba67-3406-4779-aff1-878a0e9f7885</td>\n",
       "      <td>2022-10-02</td>\n",
       "      <td>DAILY_goal1_set</td>\n",
       "      <td>Watch a historical movie</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0501ba67-3406-4779-aff1-878a0e9f7885</td>\n",
       "      <td>2022-10-03</td>\n",
       "      <td>DAILY_goal1_set</td>\n",
       "      <td>review</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0501ba67-3406-4779-aff1-878a0e9f7885</td>\n",
       "      <td>2022-10-04</td>\n",
       "      <td>DAILY_goal1_set</td>\n",
       "      <td>review</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ParticipantIdentifier  trial_date ResponseIdentifier  \\\n",
       "0  0501ba67-3406-4779-aff1-878a0e9f7885  2022-09-30    DAILY_goal1_set   \n",
       "1  0501ba67-3406-4779-aff1-878a0e9f7885  2022-10-01    DAILY_goal1_set   \n",
       "2  0501ba67-3406-4779-aff1-878a0e9f7885  2022-10-02    DAILY_goal1_set   \n",
       "3  0501ba67-3406-4779-aff1-878a0e9f7885  2022-10-03    DAILY_goal1_set   \n",
       "4  0501ba67-3406-4779-aff1-878a0e9f7885  2022-10-04    DAILY_goal1_set   \n",
       "\n",
       "                                             Answers  framing_score  \n",
       "0  Study history and psychology, practice the violin            0.0  \n",
       "1                             study history lectures            0.0  \n",
       "2                           Watch a historical movie            0.0  \n",
       "3                                             review            0.0  \n",
       "4                                             review            0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\n",
    "    'ParticipantIdentifier',\n",
    "    'trial_date',\n",
    "    'ResponseIdentifier',\n",
    "    'Answers',\n",
    "    'framing_score'\n",
    "]\n",
    "\n",
    "labelledDF = labelledDF.drop_duplicates(subset=['ParticipantIdentifier', 'trial_date', 'ResponseIdentifier'])[cols]\n",
    "labelledDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6c83611",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelledDF.to_csv('../data/proc/daily_goal_framing_long.csv', index= False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
